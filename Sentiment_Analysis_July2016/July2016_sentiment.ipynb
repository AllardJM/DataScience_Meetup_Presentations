{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##INSPIRATIONS##\n",
    "\n",
    "#http://ramhiser.com/2012/11/23/how-to-download-kaggle-data-with-python-and-requests-dot-py/\n",
    "#https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words\n",
    "#https://github.com/dandxy89/DeepLearning_MachineLearning/blob/master/EmbeddingKeras/imdb_embedding_w2v.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import zipfile, requests, StringIO\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import gensim\n",
    "import sqlite3\n",
    "import nltk\n",
    "#nltk.download() #only do this once\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525814, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Nice Taffy</td>\n",
       "      <td>I got a wild hair for taffy and ordered this five pound bag. The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc. My only complaint is there wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Great!  Just as good as the expensive brands!</td>\n",
       "      <td>This saltwater taffy had great flavors and was very soft and chewy.  Each candy was individually wrapped well.  None of the candies were stuck together, which did happen in the expensive version, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful, tasty taffy</td>\n",
       "      <td>This taffy is so good.  It is very soft and chewy.  The flavors are amazing.  I would definitely recommend you buying it.  Very satisfying!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Yay Barley</td>\n",
       "      <td>Right now I'm mostly just sprouting this so my cats can eat the grass. They love it. I rotate it around with Wheatgrass and Rye too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Healthy Dog Food</td>\n",
       "      <td>This is a very healthy dog food. Good for their digestion. Also good for small puppies. My dog eats her required amount at every feeding.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                        Summary  \\\n",
       "0      5                          Good Quality Dog Food   \n",
       "1      1                              Not as Advertised   \n",
       "2      4                          \"Delight\" says it all   \n",
       "3      2                                 Cough Medicine   \n",
       "4      5                                    Great taffy   \n",
       "5      4                                     Nice Taffy   \n",
       "6      5  Great!  Just as good as the expensive brands!   \n",
       "7      5                         Wonderful, tasty taffy   \n",
       "8      5                                     Yay Barley   \n",
       "9      5                               Healthy Dog Food   \n",
       "\n",
       "                                                                                                                                                                                                      Text  \n",
       "0  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...  \n",
       "1           Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".  \n",
       "2  This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...  \n",
       "3  If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...  \n",
       "4                                                             Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.  \n",
       "5  I got a wild hair for taffy and ordered this five pound bag. The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc. My only complaint is there wa...  \n",
       "6  This saltwater taffy had great flavors and was very soft and chewy.  Each candy was individually wrapped well.  None of the candies were stuck together, which did happen in the expensive version, ...  \n",
       "7                                                             This taffy is so good.  It is very soft and chewy.  The flavors are amazing.  I would definitely recommend you buying it.  Very satisfying!!  \n",
       "8                                                                      Right now I'm mostly just sprouting this so my cats can eat the grass. They love it. I rotate it around with Wheatgrass and Rye too  \n",
       "9                                                                This is a very healthy dog food. Good for their digestion. Also good for small puppies. My dog eats her required amount at every feeding.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##LOAD THE DATA SETS FROM KAGGLE LOCALLY##\n",
    "\n",
    "\n",
    "download_data =False\n",
    "\n",
    "# The local path where the data set is saved.\n",
    "local_filename = \"C:\\Users\\machine\\Desktop\\MeetupJuly2016\"\n",
    "\n",
    "\n",
    "if download_data:\n",
    "    \n",
    "    # Kaggle Username and Password\n",
    "    kaggle_info = {'UserName': \"XXXXX\", 'Password': \"XXXX\"}\n",
    "   \n",
    "    # The direct link to the Kaggle data set\n",
    "    data_url = ['https://www.kaggle.com/snap/amazon-fine-food-reviews/downloads/amazon-fine-foods-release-2016-01-08-20-34-54.zip']\n",
    "\n",
    "\n",
    "    for url in data_url:\n",
    "        # Attempts to download the CSV file. Gets rejected because we are not logged in.\n",
    "        r = requests.get(url)\n",
    "        # Login to Kaggle and retrieve the data.\n",
    "        r = requests.post(r.url, data = kaggle_info)\n",
    "        z = zipfile.ZipFile(StringIO.StringIO(r.content))\n",
    "        z.extractall(local_filename)\n",
    "\n",
    "\n",
    "connection = sqlite3.connect(local_filename+'\\\\amazon-fine-foods\\\\database.sqlite')\n",
    "reviews = pd.read_sql_query(\"\"\" SELECT Score, Summary, Text FROM Reviews WHERE Score != 3 \"\"\", connection)\n",
    "\n",
    "   \n",
    "print reviews.shape\n",
    "reviews.head(n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def binarize_score(score):\n",
    "    \"\"\"\n",
    "    set scores of 1-3 to 0 and 4-5 as 1\n",
    "    \"\"\"\n",
    "    \n",
    "    if score <3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##CLEAN /PROCESS REVIEWS AND RETURN LIST OR STRING##\n",
    "\n",
    "def prepare_text(raw, remove_stopwords=False, stem=False, return_string=False ):\n",
    "    \n",
    "    #1. Remove HTML and make lower case\n",
    "    cleaned = BeautifulSoup(raw,\"lxml\").get_text().lower()\n",
    "    \n",
    "    #perhaps useful for sentiment analysis.....\n",
    "    #2. Replace numbers, smiliey and frown faces, ! and ? with coded word SM{int} in case these are valuable\n",
    "    cleaned=re.sub(r'[0-9]+',r' DEG', cleaned) #replace numbers with a token\n",
    "    cleaned=re.sub(\"(:\\))\",r' SM1',cleaned) #smiley\n",
    "    cleaned=re.sub(\"(:\\()\",r' SM2',cleaned) #frown\n",
    "    cleaned=re.sub(\"(!)\",r' SM3',cleaned) #exclame\n",
    "    cleaned=re.sub(\"(\\?)\",r' SM4',cleaned) #question\n",
    "    \n",
    "    cleaned=re.sub(\"'s\",\"\",cleaned) #remove 's\n",
    "    cleaned=re.sub(\"'\",\"\",cleaned) #remove '\n",
    "    \n",
    "    \n",
    "    #3. keep 'not' and the next word as negation may be important.\n",
    "    cleaned=re.sub(r\"not\\s\\b(.*?)\\b\", r\"not_\\1\", cleaned)\n",
    "    \n",
    "    \n",
    "    #4.keep letters (hyphens) and the coded tokens above, replace the rest with whitespace\n",
    "    cleaned=re.sub(\"[^\\-a-zA-ZSM\\d]\",\" \",cleaned)  \n",
    "    \n",
    "    #5.Split into individual words on whitespace\n",
    "    cleaned = cleaned.split()                             \n",
    "    \n",
    "      \n",
    "    #6.Remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\")) \n",
    "        cleaned = [w for w in cleaned if not w in stops]   \n",
    "   \n",
    "    #7. Stem\n",
    "    if stem:\n",
    "        cleaned=[porter_stemmer.stem(w) for w in cleaned]\n",
    "        \n",
    "    \n",
    "    #8.Concatenate back to a string?\n",
    "    if return_string:\n",
    "        cleaned= \" \".join( cleaned )\n",
    "    \n",
    "    return(cleaned)\n",
    "\n",
    "\n",
    "\n",
    "##RETURN LIST OF TOKENS##\n",
    "def token_list(raw_string):\n",
    "    tokens=raw_string.split()\n",
    "              \n",
    "    return tokens\n",
    "\n",
    "\n",
    "\n",
    "##RETURN PERFORMANCE FOR BINARY CLASSIFIER##\n",
    "\n",
    "def binary_perform(true,pred):\n",
    "    print 'AUC: ',metrics.roc_auc_score(true,pred)\n",
    "    print 'Accuracy: ', metrics.accuracy_score(true,(pred>0.5))\n",
    "    return (pd.DataFrame(metrics.confusion_matrix(true,(pred>0.5)),index=['True_NEG','True_POS'],columns=['Pred_NEG','Pred_POS']))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "##AVERAGE WORD VECTORS##\n",
    "def avg_word_vectors(wordlist,model,size):\n",
    "    \"\"\"\n",
    "    returns a vector of zero for reviews containing words where none of them\n",
    "    met the min_count or were not seen in the training set\n",
    "    \n",
    "    Otherwise return an average of the embeddings vectors\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sumvec=np.zeros(shape=(1,size)) #initialize correct size zero vector\n",
    "    wordcnt=0\n",
    "    \n",
    "    for w in wordlist:\n",
    "        if w in model: #if the word is in the word2vec model\n",
    "            sumvec += model[w] #add to sum vector\n",
    "            wordcnt +=1  #incremental counter\n",
    "    \n",
    "    sumvec=pd.Series(sumvec.reshape(size,))\n",
    "    \n",
    "    if wordcnt ==0:\n",
    "        return sumvec\n",
    "    \n",
    "    else:\n",
    "        return sumvec / wordcnt\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Clean and process the reviews </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\machine\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:198: UserWarning: \"...\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  '\"%s\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.' % markup)\n",
      "C:\\Users\\machine\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:207: UserWarning: \"http://www.amazon.com/gp/product/B007I7YYGY/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "C:\\Users\\machine\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:198: UserWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  '\"%s\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.' % markup)\n",
      "C:\\Users\\machine\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:207: UserWarning: \"http://www.amazon.com/gp/product/B001EQ58FQ/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "##CLEAN AND PROCESS REVIEWS - BOTH AS LIST AND STRING ##\n",
    "##NOT STEM TO ALLOW BETTER WORD SIM UNDERSTANDING##\n",
    "\n",
    "reviews['Score_binary']=reviews['Score'].apply(binarize_score)\n",
    "\n",
    "reviews['summary_str']=reviews['Summary'].apply(prepare_text,remove_stopwords=True,stem=False, return_string=True)\n",
    "reviews['summary_lst']=reviews['summary_str'].apply(token_list)\n",
    "\n",
    "reviews['text_str']=reviews['Text'].apply(prepare_text,remove_stopwords=True, stem=False,return_string=True)\n",
    "reviews['text_lst']=reviews['text_str'].apply(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Score_binary</th>\n",
       "      <th>summary_str</th>\n",
       "      <th>summary_lst</th>\n",
       "      <th>text_str</th>\n",
       "      <th>text_lst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...</td>\n",
       "      <td>1</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>[good, quality, dog, food]</td>\n",
       "      <td>bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better</td>\n",
       "      <td>[bought, several, vitality, canned, dog, food, products, found, good, quality, product, looks, like, stew, processed, meat, smells, better, labrador, finicky, appreciates, product, better]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</td>\n",
       "      <td>0</td>\n",
       "      <td>advertised</td>\n",
       "      <td>[advertised]</td>\n",
       "      <td>product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo</td>\n",
       "      <td>[product, arrived, labeled, jumbo, salted, peanuts, peanuts, actually, small, sized, unsalted, sure, error, vendor, intended, represent, product, jumbo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>delight says</td>\n",
       "      <td>[delight, says]</td>\n",
       "      <td>confection around centuries light pillowy citrus gelatin nuts - case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat fam...</td>\n",
       "      <td>[confection, around, centuries, light, pillowy, citrus, gelatin, nuts, -, case, filberts, cut, tiny, squares, liberally, coated, powdered, sugar, tiny, mouthful, heaven, chewy, flavorful, highly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...</td>\n",
       "      <td>0</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>[cough, medicine]</td>\n",
       "      <td>looking secret ingredient robitussin believe found got addition root beer extract ordered good made cherry soda flavor medicinal</td>\n",
       "      <td>[looking, secret, ingredient, robitussin, believe, found, got, addition, root, beer, extract, ordered, good, made, cherry, soda, flavor, medicinal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.</td>\n",
       "      <td>1</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>[great, taffy]</td>\n",
       "      <td>great taffy great price wide assortment yummy taffy delivery quick taffy lover deal</td>\n",
       "      <td>[great, taffy, great, price, wide, assortment, yummy, taffy, delivery, quick, taffy, lover, deal]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                Summary  \\\n",
       "0      5  Good Quality Dog Food   \n",
       "1      1      Not as Advertised   \n",
       "2      4  \"Delight\" says it all   \n",
       "3      2         Cough Medicine   \n",
       "4      5            Great taffy   \n",
       "\n",
       "                                                                                                                                                                                                      Text  \\\n",
       "0  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...   \n",
       "1           Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".   \n",
       "2  This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...   \n",
       "3  If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...   \n",
       "4                                                             Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.   \n",
       "\n",
       "   Score_binary            summary_str                 summary_lst  \\\n",
       "0             1  good quality dog food  [good, quality, dog, food]   \n",
       "1             0             advertised                [advertised]   \n",
       "2             1           delight says             [delight, says]   \n",
       "3             0         cough medicine           [cough, medicine]   \n",
       "4             1            great taffy              [great, taffy]   \n",
       "\n",
       "                                                                                                                                                                                                  text_str  \\\n",
       "0                                     bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better   \n",
       "1                                                                    product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo   \n",
       "2  confection around centuries light pillowy citrus gelatin nuts - case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat fam...   \n",
       "3                                                                         looking secret ingredient robitussin believe found got addition root beer extract ordered good made cherry soda flavor medicinal   \n",
       "4                                                                                                                      great taffy great price wide assortment yummy taffy delivery quick taffy lover deal   \n",
       "\n",
       "                                                                                                                                                                                                  text_lst  \n",
       "0             [bought, several, vitality, canned, dog, food, products, found, good, quality, product, looks, like, stew, processed, meat, smells, better, labrador, finicky, appreciates, product, better]  \n",
       "1                                                 [product, arrived, labeled, jumbo, salted, peanuts, peanuts, actually, small, sized, unsalted, sure, error, vendor, intended, represent, product, jumbo]  \n",
       "2  [confection, around, centuries, light, pillowy, citrus, gelatin, nuts, -, case, filberts, cut, tiny, squares, liberally, coated, powdered, sugar, tiny, mouthful, heaven, chewy, flavorful, highly, ...  \n",
       "3                                                      [looking, secret, ingredient, robitussin, believe, found, got, addition, root, beer, extract, ordered, good, made, cherry, soda, flavor, medicinal]  \n",
       "4                                                                                                        [great, taffy, great, price, wide, assortment, yummy, taffy, delivery, quick, taffy, lover, deal]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (420651, 8)\n",
      "y_train shape:  (420651L,)\n",
      "X_test shape:  (105163, 8)\n",
      "y_test shape:  (105163L,)\n",
      "Columns in X:  Index([u'Score', u'Summary', u'Text', u'Score_binary', u'summary_str',\n",
      "       u'summary_lst', u'text_str', u'text_lst'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "##TRAIN AND TEST##\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, reviews.Score_binary, test_size=0.20, random_state=64)\n",
    "\n",
    "print 'X_train shape: ',X_train.shape\n",
    "print 'y_train shape: ',y_train.shape\n",
    "print 'X_test shape: ',X_test.shape\n",
    "print 'y_test shape: ',y_test.shape\n",
    "\n",
    "print 'Columns in X: ',X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>This is the classic TFIDF linear model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tfid shape:  (420651, 25929)\n",
      "X_test shape:  (105163, 25929)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,1),max_df=0.80, min_df=5) #these parameters \n",
    "                                                                    #should be optimized further!\n",
    "vectorizer.fit(X_train.text_str)\n",
    "X_train_tfid=vectorizer.transform(X_train.text_str)\n",
    "X_test_tfid=vectorizer.transform(X_test.text_str)\n",
    "\n",
    "print 'X_train_tfid shape: ',X_train_tfid.shape\n",
    "print 'X_test shape: ',X_test_tfid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.962539264655\n",
      "Accuracy:  0.935928035526\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred_NEG</th>\n",
       "      <th>Pred_POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True_NEG</th>\n",
       "      <td>12195</td>\n",
       "      <td>4319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True_POS</th>\n",
       "      <td>2419</td>\n",
       "      <td>86230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred_NEG  Pred_POS\n",
       "True_NEG     12195      4319\n",
       "True_POS      2419     86230"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##FIT A BASIC REGULARIZED LOGISTIC REGRESSION##\n",
    "\n",
    "LRcv=LogisticRegressionCV(cv=5) #use 5-fold cv to find regularization parameter C \n",
    "                                #(smaller C = more regularization)\n",
    "LRcv.fit(X_train_tfid,y_train)\n",
    "\n",
    "#predict test set\n",
    "preds_LR = LRcv.predict_proba(X_test_tfid)[:,1]\n",
    "\n",
    "#performance\n",
    "binary_perform(y_test,preds_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>Train Word2Vec</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train word2vec using skipgram model (sg=1), sampling 10 negative examples (negative=10)\n",
    "#400 dimensional word vectors (size=400), window size of 5 words on each side (window=5)\n",
    "#words have to be seen atleast 5 times across all documents (min_count=5)\n",
    "\n",
    "\n",
    "model_w2v = gensim.models.Word2Vec(X_train.text_lst,sg=1, negative=10, size=400, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.23606861e-01,  -2.68316627e-01,   2.98433360e-02,\n",
       "        -2.98076477e-02,  -1.19921602e-01,   1.98405474e-01,\n",
       "         1.50522530e-01,   1.11300781e-01,   6.35064617e-02,\n",
       "         1.39275640e-01,   8.23053345e-02,   1.77483201e-01,\n",
       "        -7.47933537e-02,  -2.06616428e-02,   3.54353734e-03,\n",
       "        -4.15252447e-02,  -8.61085504e-02,   1.58804003e-03,\n",
       "         9.39110592e-02,  -1.70067266e-01,  -7.99810365e-02,\n",
       "        -4.85614017e-02,   2.99121857e-01,  -1.58234909e-02,\n",
       "        -5.69150201e-04,   9.85797867e-02,  -2.13606358e-01,\n",
       "        -1.57882750e-01,  -1.49433687e-01,  -1.72859594e-01,\n",
       "         2.11090073e-02,   1.79099903e-01,   1.27554843e-02,\n",
       "         1.92327932e-01,  -8.08020234e-02,  -2.29380384e-01,\n",
       "        -1.03765607e-01,  -9.97763593e-04,  -5.28124869e-02,\n",
       "        -4.51258004e-01,   3.30734823e-04,   1.48674130e-01,\n",
       "        -2.62362659e-01,  -3.93698998e-02,   6.72200695e-02,\n",
       "         1.88156322e-01,  -1.53170601e-01,  -2.27943912e-01,\n",
       "        -1.24653969e-02,   4.76006940e-02,   5.84265366e-02,\n",
       "         1.28811106e-01,   1.29281700e-01,  -8.52525160e-02,\n",
       "         4.00390998e-02,  -5.47840111e-02,  -1.48993000e-01,\n",
       "         5.15147932e-02,  -1.80777870e-02,   4.50478531e-02,\n",
       "        -7.94197097e-02,  -3.43160331e-02,   3.38684738e-01,\n",
       "        -1.68649629e-01,   6.61174804e-02,   1.57748297e-01,\n",
       "        -2.26744771e-01,  -1.42990304e-02,   2.00406075e-01,\n",
       "         1.99105918e-01,   3.76858562e-01,  -9.30804536e-02,\n",
       "        -2.91479260e-01,   8.49524513e-02,  -2.32135616e-02,\n",
       "        -4.56267655e-01,   3.66207175e-02,   1.58845201e-01,\n",
       "         4.24922556e-02,   3.65387887e-01,   2.40890533e-02,\n",
       "        -2.05532730e-01,   1.17041618e-01,   1.81886315e-01,\n",
       "        -2.27482632e-01,  -1.21654920e-01,   5.74951023e-02,\n",
       "         4.44309153e-02,   1.87526152e-01,  -1.20395638e-01,\n",
       "        -3.41542691e-01,  -4.56281975e-02,   1.58697620e-01,\n",
       "        -1.22640535e-01,   1.10999234e-01,   2.56854504e-01,\n",
       "         1.69571806e-02,   4.78950627e-02,   1.96456224e-01,\n",
       "         7.27657825e-02,  -4.13619541e-02,   7.56712258e-02,\n",
       "        -2.53826976e-01,  -1.10988833e-01,  -1.33939996e-01,\n",
       "        -2.32457459e-01,   1.35548875e-01,   1.46878585e-01,\n",
       "        -3.37114297e-02,   1.05277203e-01,  -1.13137305e-01,\n",
       "        -1.63092446e-02,  -9.36097056e-02,  -2.36059576e-01,\n",
       "        -1.79908887e-01,  -5.01497090e-02,  -1.72866836e-01,\n",
       "         4.20465022e-02,   1.13376163e-01,  -3.33116539e-02,\n",
       "         1.63842350e-01,   1.07898392e-01,  -1.21321470e-01,\n",
       "         3.56990188e-01,  -4.30565998e-02,   1.55482426e-01,\n",
       "         1.26629904e-01,  -2.13430434e-01,   6.05543368e-02,\n",
       "         1.93159431e-01,   3.71770673e-02,  -2.55637527e-01,\n",
       "         5.29242642e-02,   1.27367660e-01,  -3.01824603e-02,\n",
       "        -8.94992128e-02,   4.36718874e-02,  -1.59058526e-01,\n",
       "         8.40785056e-02,   5.01858890e-02,   2.72018075e-01,\n",
       "         8.96197408e-02,  -7.46284379e-03,  -5.30156493e-02,\n",
       "         4.69944537e-01,   1.76343527e-02,  -1.15235366e-01,\n",
       "         7.30300322e-02,   7.05348477e-02,   2.79417545e-01,\n",
       "         1.17370054e-01,   2.00007513e-01,  -2.39449039e-01,\n",
       "         6.94867671e-02,  -1.01843990e-01,  -3.25261354e-02,\n",
       "        -1.44268021e-01,  -5.47227673e-02,  -1.79256778e-02,\n",
       "        -2.86222011e-01,  -3.66456330e-01,   2.89311945e-01,\n",
       "        -5.44195287e-02,  -2.02698082e-01,  -2.45317936e-01,\n",
       "        -1.42873107e-02,  -4.95680831e-02,   2.20026717e-01,\n",
       "        -8.15635175e-02,  -2.66675830e-01,   3.96364965e-02,\n",
       "         2.42420629e-01,  -1.81297772e-02,   2.15679690e-01,\n",
       "        -2.41210192e-01,  -1.67356674e-02,   3.01387347e-02,\n",
       "        -3.57871838e-02,   6.44728616e-02,   5.80498837e-02,\n",
       "        -8.31412375e-02,  -1.06946908e-01,  -3.68571691e-02,\n",
       "        -2.11678296e-01,   2.95087695e-01,  -2.54927367e-01,\n",
       "         1.93916813e-01,  -1.11478724e-01,   3.03620249e-01,\n",
       "        -1.38086267e-02,  -3.96292880e-02,   1.51603706e-02,\n",
       "        -2.69002467e-01,  -1.11444909e-02,  -3.34436968e-02,\n",
       "        -3.03497482e-02,  -1.26132548e-01,   1.30742475e-01,\n",
       "        -5.42863719e-02,  -3.15500766e-01,   8.83537456e-02,\n",
       "        -3.19787353e-01,   9.05439854e-02,  -1.15368865e-01,\n",
       "         1.55057728e-01,   1.36691481e-01,   4.35178190e-01,\n",
       "         2.78165657e-02,  -8.47137198e-02,   1.23850130e-01,\n",
       "         1.48420349e-01,   2.01276287e-01,   2.84123838e-01,\n",
       "        -1.02916725e-01,   6.64220005e-02,   1.23425521e-01,\n",
       "         3.41172993e-01,  -7.30359331e-02,   1.45810351e-01,\n",
       "         1.16365433e-01,   1.48943856e-01,   1.44802630e-01,\n",
       "        -2.97956884e-01,   4.46637422e-02,  -1.72910094e-01,\n",
       "         9.73284319e-02,   1.51435107e-01,  -2.32333302e-01,\n",
       "        -1.66181505e-01,  -2.08928566e-02,  -7.22519085e-02,\n",
       "        -1.80246130e-01,  -3.05415094e-01,   3.01716421e-02,\n",
       "        -8.80378187e-02,   1.48772746e-01,   1.02938607e-01,\n",
       "        -2.21390501e-01,   1.72449693e-01,   1.24484971e-02,\n",
       "         1.64029375e-01,   1.44074842e-01,   1.93156555e-01,\n",
       "        -3.99486646e-02,  -1.03861041e-01,  -1.03420177e-02,\n",
       "        -5.13477884e-02,   1.12358712e-01,   2.34956387e-02,\n",
       "         2.48458460e-01,   1.39302880e-01,  -8.78560022e-02,\n",
       "        -9.15137976e-02,   2.55324692e-01,   4.73897792e-02,\n",
       "        -1.46245137e-01,   4.90576364e-02,   2.34155639e-04,\n",
       "        -1.78795204e-01,  -6.39310181e-02,  -1.30428672e-01,\n",
       "        -2.03663334e-01,  -3.07813525e-01,  -7.50644598e-03,\n",
       "        -6.91299289e-02,  -5.66012375e-02,   3.71468633e-01,\n",
       "         4.65864688e-02,   2.22376406e-01,  -1.01687811e-01,\n",
       "         4.80846167e-02,   1.04022704e-01,  -6.36966005e-02,\n",
       "        -1.36798710e-01,   1.15022466e-01,   8.57392251e-02,\n",
       "         8.40154961e-02,  -1.97838426e-01,  -3.87490928e-01,\n",
       "         1.44683704e-01,   4.11859639e-02,   4.03647833e-02,\n",
       "         3.22008729e-01,  -6.88701943e-02,   1.26025677e-01,\n",
       "         1.55677378e-01,   7.93356672e-02,  -1.89334363e-01,\n",
       "         4.51094322e-02,  -2.17602387e-01,   3.30041535e-02,\n",
       "        -3.05457324e-01,  -2.23360598e-01,  -1.10874891e-01,\n",
       "         6.47753403e-02,  -1.41653448e-01,  -2.26944640e-01,\n",
       "         9.67398509e-02,   2.19809730e-02,   2.51730144e-01,\n",
       "         1.54599518e-01,   2.42742658e-01,   7.75291473e-02,\n",
       "         2.31123082e-02,  -4.26141880e-02,  -9.88477468e-02,\n",
       "         1.04560889e-01,  -9.14401338e-02,  -1.52924508e-02,\n",
       "         2.08892658e-01,  -3.67801376e-02,  -4.20278549e-01,\n",
       "         1.79752596e-02,   4.31561396e-02,   7.36785382e-02,\n",
       "         5.73503859e-02,  -2.20604822e-01,  -3.66281688e-01,\n",
       "        -8.64819810e-03,  -2.10296195e-02,   8.07086676e-02,\n",
       "        -7.61009008e-02,  -2.95514643e-01,   4.18301731e-01,\n",
       "        -1.45311370e-01,   4.45744721e-03,  -3.15193862e-01,\n",
       "         3.66301149e-01,   5.60336970e-02,  -6.21143766e-02,\n",
       "        -5.43560535e-02,  -7.87564740e-02,  -5.54299280e-02,\n",
       "         3.01215291e-01,   1.55386046e-01,   1.89310849e-01,\n",
       "        -5.97869940e-02,   5.08685298e-02,   7.46902674e-02,\n",
       "        -2.48839557e-01,   1.87720343e-01,   2.67333597e-01,\n",
       "         1.32006928e-01,  -9.43036377e-02,  -2.40659237e-01,\n",
       "        -1.20927311e-01,  -3.49883854e-01,   3.80538218e-02,\n",
       "         2.13966146e-02,  -1.75376400e-01,   7.41670877e-02,\n",
       "         1.20855756e-01,  -2.94258050e-03,  -1.39619946e-01,\n",
       "        -1.16028212e-01,   1.42519116e-01,   2.42851824e-01,\n",
       "        -1.05502397e-01,   1.01230226e-01,   1.17671927e-02,\n",
       "        -2.80025810e-01,   6.05592430e-02,   5.95008321e-02,\n",
       "         1.30379826e-01,   1.61883086e-01,  -5.56305163e-02,\n",
       "         2.82948818e-02,   5.89527115e-02,  -7.07167992e-03,\n",
       "        -3.10936779e-01,  -5.70196882e-02,  -2.80450173e-02,\n",
       "        -2.23803788e-01,   7.54190981e-02,   2.60832496e-02,\n",
       "        -2.58666910e-02,  -3.62972803e-02,  -3.46432000e-01,\n",
       "        -2.38183606e-02,  -1.65612727e-01,   1.45093501e-01,\n",
       "         2.42859293e-02,  -3.82414669e-01,  -1.28648520e-01,\n",
       "        -1.71961606e-01,   3.18346918e-01,   1.36092737e-01,\n",
       "        -3.21268775e-02,   1.10240825e-01,  -1.79549113e-01,\n",
       "         1.97693214e-01,  -2.60041267e-01,  -9.97105986e-02,\n",
       "        -1.21060893e-01,   2.26065159e-01,  -1.44398794e-01,\n",
       "         6.64052516e-02,   2.26467595e-01,  -1.77167132e-01,\n",
       "         2.45344505e-01], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v['bad'] #400 dimensional vector represents the word 'bad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'terrible', 0.4946768283843994),\n",
       " (u'cruddy', 0.4914777874946594),\n",
       " (u'woah', 0.48704078793525696),\n",
       " (u'bad-', 0.48413723707199097),\n",
       " (u'heyyyy', 0.4811605215072632),\n",
       " (u'nasty', 0.4763026833534241),\n",
       " (u'allerges', 0.4748576879501343),\n",
       " (u'version-', 0.4692271947860718),\n",
       " (u'rap', 0.4672160744667053),\n",
       " (u'short-changed', 0.46421128511428833),\n",
       " (u'rowdy', 0.46168819069862366),\n",
       " (u'undeserved', 0.46112364530563354),\n",
       " (u'plastic-y', 0.4593057930469513),\n",
       " (u'effecting', 0.4588324725627899),\n",
       " (u'bizarrely', 0.4578687846660614),\n",
       " (u'awry', 0.45783835649490356),\n",
       " (u'jtc', 0.45778846740722656),\n",
       " (u'good', 0.4556412696838379),\n",
       " (u'mediciny', 0.4542664885520935),\n",
       " (u'fine-so', 0.45211514830589294),\n",
       " (u'overdried', 0.44963207840919495),\n",
       " (u'first--great', 0.44939422607421875),\n",
       " (u'punish', 0.4482073187828064),\n",
       " (u'odder', 0.44737327098846436),\n",
       " (u'repulsive', 0.44680100679397583)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.most_similar(['bad'],topn=25) #top 25 words most similiar to bad vector \n",
    "                                        #(probably need more training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420651, 400)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11548</th>\n",
       "      <td>-0.027505</td>\n",
       "      <td>-0.109973</td>\n",
       "      <td>-0.178321</td>\n",
       "      <td>-0.002176</td>\n",
       "      <td>-0.009496</td>\n",
       "      <td>-0.055786</td>\n",
       "      <td>-0.001330</td>\n",
       "      <td>-0.033730</td>\n",
       "      <td>0.049621</td>\n",
       "      <td>0.038980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123395</td>\n",
       "      <td>-0.215210</td>\n",
       "      <td>-0.109778</td>\n",
       "      <td>0.068481</td>\n",
       "      <td>0.090897</td>\n",
       "      <td>0.060064</td>\n",
       "      <td>-0.054043</td>\n",
       "      <td>0.146011</td>\n",
       "      <td>-0.063310</td>\n",
       "      <td>0.060052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328858</th>\n",
       "      <td>0.055390</td>\n",
       "      <td>-0.030188</td>\n",
       "      <td>-0.104777</td>\n",
       "      <td>-0.056711</td>\n",
       "      <td>0.043442</td>\n",
       "      <td>-0.011004</td>\n",
       "      <td>0.042148</td>\n",
       "      <td>-0.058843</td>\n",
       "      <td>0.092274</td>\n",
       "      <td>-0.018265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104028</td>\n",
       "      <td>-0.127704</td>\n",
       "      <td>-0.038870</td>\n",
       "      <td>0.061692</td>\n",
       "      <td>0.101253</td>\n",
       "      <td>0.060593</td>\n",
       "      <td>0.033210</td>\n",
       "      <td>0.213583</td>\n",
       "      <td>-0.022627</td>\n",
       "      <td>0.022856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454122</th>\n",
       "      <td>0.014845</td>\n",
       "      <td>0.081913</td>\n",
       "      <td>-0.186295</td>\n",
       "      <td>-0.080111</td>\n",
       "      <td>-0.011029</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>0.074054</td>\n",
       "      <td>-0.049991</td>\n",
       "      <td>0.138257</td>\n",
       "      <td>-0.012932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064803</td>\n",
       "      <td>-0.038005</td>\n",
       "      <td>-0.093770</td>\n",
       "      <td>0.055847</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>-0.004128</td>\n",
       "      <td>0.008277</td>\n",
       "      <td>0.111504</td>\n",
       "      <td>-0.035020</td>\n",
       "      <td>0.035007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463521</th>\n",
       "      <td>0.057556</td>\n",
       "      <td>-0.061966</td>\n",
       "      <td>-0.098184</td>\n",
       "      <td>-0.032439</td>\n",
       "      <td>-0.051118</td>\n",
       "      <td>-0.038383</td>\n",
       "      <td>0.038852</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.066702</td>\n",
       "      <td>0.058439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121871</td>\n",
       "      <td>-0.261655</td>\n",
       "      <td>-0.046266</td>\n",
       "      <td>0.023426</td>\n",
       "      <td>0.146100</td>\n",
       "      <td>0.068661</td>\n",
       "      <td>0.007724</td>\n",
       "      <td>0.137245</td>\n",
       "      <td>-0.004498</td>\n",
       "      <td>-0.047226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63873</th>\n",
       "      <td>-0.001678</td>\n",
       "      <td>-0.135287</td>\n",
       "      <td>-0.145270</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.003390</td>\n",
       "      <td>-0.125997</td>\n",
       "      <td>0.093370</td>\n",
       "      <td>-0.007090</td>\n",
       "      <td>0.085538</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133823</td>\n",
       "      <td>-0.214508</td>\n",
       "      <td>0.023021</td>\n",
       "      <td>0.050308</td>\n",
       "      <td>0.109792</td>\n",
       "      <td>0.025889</td>\n",
       "      <td>-0.065633</td>\n",
       "      <td>0.188860</td>\n",
       "      <td>-0.059327</td>\n",
       "      <td>-0.001370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "11548  -0.027505 -0.109973 -0.178321 -0.002176 -0.009496 -0.055786 -0.001330   \n",
       "328858  0.055390 -0.030188 -0.104777 -0.056711  0.043442 -0.011004  0.042148   \n",
       "454122  0.014845  0.081913 -0.186295 -0.080111 -0.011029  0.005394  0.074054   \n",
       "463521  0.057556 -0.061966 -0.098184 -0.032439 -0.051118 -0.038383  0.038852   \n",
       "63873  -0.001678 -0.135287 -0.145270 -0.000330 -0.003390 -0.125997  0.093370   \n",
       "\n",
       "             7         8         9      ...          390       391       392  \\\n",
       "11548  -0.033730  0.049621  0.038980    ...     0.123395 -0.215210 -0.109778   \n",
       "328858 -0.058843  0.092274 -0.018265    ...     0.104028 -0.127704 -0.038870   \n",
       "454122 -0.049991  0.138257 -0.012932    ...     0.064803 -0.038005 -0.093770   \n",
       "463521  0.003071  0.066702  0.058439    ...     0.121871 -0.261655 -0.046266   \n",
       "63873  -0.007090  0.085538  0.019231    ...     0.133823 -0.214508  0.023021   \n",
       "\n",
       "             393       394       395       396       397       398       399  \n",
       "11548   0.068481  0.090897  0.060064 -0.054043  0.146011 -0.063310  0.060052  \n",
       "328858  0.061692  0.101253  0.060593  0.033210  0.213583 -0.022627  0.022856  \n",
       "454122  0.055847  0.002942 -0.004128  0.008277  0.111504 -0.035020  0.035007  \n",
       "463521  0.023426  0.146100  0.068661  0.007724  0.137245 -0.004498 -0.047226  \n",
       "63873   0.050308  0.109792  0.025889 -0.065633  0.188860 -0.059327 -0.001370  \n",
       "\n",
       "[5 rows x 400 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##AVERAGE WORD VECTORS FOR EACH REVIEW##\n",
    "\n",
    "X_train_avg=X_train.text_lst.apply(avg_word_vectors,model=model_w2v,size=400)\n",
    "X_test_avg=X_test.text_lst.apply(avg_word_vectors,model=model_w2v,size=400)\n",
    "\n",
    "print X_train_avg.shape\n",
    "X_train_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.946360363942\n",
      "Accuracy:  0.920580432281\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred_NEG</th>\n",
       "      <th>Pred_POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True_NEG</th>\n",
       "      <td>10597</td>\n",
       "      <td>5917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True_POS</th>\n",
       "      <td>2435</td>\n",
       "      <td>86214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred_NEG  Pred_POS\n",
       "True_NEG     10597      5917\n",
       "True_POS      2435     86214"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TRAIN SAME TYPE OF REGULARIZED LOGISTIC REGRESSION##\n",
    "\n",
    "LRcv_w2v=LogisticRegressionCV(cv=5) #use 5-fold cv to find regularization \n",
    "                                    #parameter C (smaller C = more regularization)\n",
    "LRcv_w2v.fit(X_train_avg,y_train)\n",
    "\n",
    "#predict test set\n",
    "preds_LR_w2v = LRcv_w2v.predict_proba(X_test_avg)[:,1]\n",
    "\n",
    "#performance\n",
    "binary_perform(y_test,preds_LR_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LSTM RNN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "np.random.seed(1337) # sets seed used by Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be really powerful but we will wait for a week without a GPU......So we will sample and run the code just as illustration. The performance is pretty good for only being trained on a small number of records, for a few epochs and with a simple model - we could add additional layers, play around with learning rates etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gensim_dict = Dictionary() #empty dictionary class from gensim  mapping between words and their integer ids\n",
    "\n",
    "\"\"\"\n",
    "model_w2v.vocab.keys() is a list of all tokens from the word2vec model\n",
    "add to the dictionary each token from word2vec model\n",
    "doc2bow will create a mapping of  the word list to (token_id, token_count) 2-tuples\n",
    "\"\"\"\n",
    "gensim_dict.doc2bow(model_w2v.vocab.keys(),allow_update=True)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "now our gensim_dict will allow us to iterate through each token and its assigned integer id\n",
    "gensim_dict.items() return list of tuples of int ID and word.... \n",
    "[(0, u'individual-sized'),\n",
    " (1, u'woods'),\n",
    " (2, u'clotted'),\n",
    " .........\n",
    "]\n",
    "\n",
    "w2indx is a dictionary with the word as the key and integer id as the value\n",
    "(note this is same as gensim_dict.id2token but reversing key and value)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "w2indx = {v: k+1 for k, v in gensim_dict.items()} #adding 1 to not use zero which will be used as padding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parsedata(word_list):\n",
    "    new_list=[]\n",
    "    for word in word_list: #for each word in the list of words\n",
    "        try:\n",
    "            new_list.append(w2indx[word]) #append the integer mapped to the word to the list \n",
    "        except:\n",
    "            new_list.append(0) #else add zero vector if the word was not found\n",
    "    return new_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=X_train.text_lst.apply(parsedata)\n",
    "test=X_test.text_lst.apply(parsedata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_symbols =len(w2indx)+1 #number of words plus 1 for zero (padding)\n",
    "vocab_dim = 400 #size of word2vec word embeddings\n",
    "\n",
    "\n",
    "embedding_weights = np.zeros((n_symbols, vocab_dim))\n",
    "\n",
    "for word, index in w2indx.iteritems():\n",
    "    embedding_weights[index, :] = model_w2v[word] #doesnt use index of 0 since that was not created in model_w2v dictionary\n",
    "\n",
    "embedding_weights=[embedding_weights] #keras expects as a list with a single element of size (n_symbols, vocab_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxlen=50 #longest word list to allow - pad with zero to the left\n",
    "\n",
    "train = sequence.pad_sequences(train.values, maxlen=maxlen) #use values to get the arrays from pandas\n",
    "test = sequence.pad_sequences(test.values, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,  4419,     0, 37190, 41767, 26184, 24983,\n",
       "       22817, 24541, 15862, 16647,  6826, 21248,  6376, 15093, 22140,\n",
       "       22789, 15516, 35281,  7006, 41225, 41767,  6173, 32635, 23604,\n",
       "       36496, 11819,  5038, 22789, 12785])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train2 shape:  (210325L, 50L)\n",
      "y_train2 shape:  (210325L,)\n",
      "val shape:  (210326L, 50L)\n",
      "y_val shape:  (210326L,)\n"
     ]
    }
   ],
   "source": [
    "#sample 50% of train to build a model without GPU\n",
    "train2, val, y_train2, y_val = train_test_split(train, y_train, test_size=0.50, random_state=64)\n",
    "print 'train2 shape: ',train2.shape\n",
    "print 'y_train2 shape: ',y_train2.shape\n",
    "print 'val shape: ',val.shape\n",
    "print 'y_val shape: ',y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 210325 samples, validate on 210326 samples\n",
      "Epoch 1/3\n",
      "210325/210325 [==============================] - 8394s - loss: 0.2003 - val_loss: 0.1561\n",
      "Epoch 2/3\n",
      "210325/210325 [==============================] - 8826s - loss: 0.1302 - val_loss: 0.1526\n",
      "Epoch 3/3\n",
      "210325/210325 [==============================] - 30554s - loss: 0.0885 - val_loss: 0.1624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11c6b48d0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()  \n",
    "model.add(Embedding(output_dim=vocab_dim,\n",
    "                    input_dim=n_symbols,\n",
    "                    mask_zero=True,\n",
    "                    weights=embedding_weights,\n",
    "                    input_length=maxlen))  \n",
    "model.add(LSTM(vocab_dim))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam')\n",
    "\n",
    "model.fit(x=train2, y=y_train2, validation_data= (val,y_val), batch_size=128, nb_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105163/105163 [==============================] - 843s   \n"
     ]
    }
   ],
   "source": [
    "p=model.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.968653307164\n",
      "Accuracy:  0.945560701007\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred_NEG</th>\n",
       "      <th>Pred_POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True_NEG</th>\n",
       "      <td>13657</td>\n",
       "      <td>2857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True_POS</th>\n",
       "      <td>2868</td>\n",
       "      <td>85781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred_NEG  Pred_POS\n",
       "True_NEG     13657      2857\n",
       "True_POS      2868     85781"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performance\n",
    "binary_perform(y_test,p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
